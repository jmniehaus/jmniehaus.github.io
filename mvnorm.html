<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>MV Norm Draws</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

.sourceCode .row {
  width: 100%;
}
.sourceCode {
  overflow-x: auto;
}
.code-folding-btn {
  margin-right: -30px;
}
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">John M. Niehaus</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="./files/niehaus_cv_2022_online.pdf">Resume</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Programming &amp; Derivations
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="irls.html">Iteratively Reweighted Least Squares for GLMs</a>
    </li>
    <li>
      <a href="mvnorm.html">Multivariate Normal Draws</a>
    </li>
    <li>
      <a href="montes.html">Monte Carlo Analysis using R, with Examples</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="http://github.com/jmniehaus">
    <span class="fab fa-github"></span>
     
    GitHub
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/john-niehaus/">
    <span class="fa fa-brands fa-linkedin"></span>
     
    LinkedIn
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Drawing from the Multivariate Normal
Distribution</h1>
<h3 class="subtitle">Derivation, and Programming in R</h3>
<h4 class="date">Updated: 26 Feb 2021</h4>

</div>


<style>

.list-group-item.active, .list-group-item.active:focus, .list-group-item.active:hover {
    background-color: SlateGrey;
}

.nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li.active>a:focus, .nav-pills>li.active>a:link {
    background-color: SlateGrey;
    color: white
}
.nav-pills>li>a:link{
    color: black
}

</style>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: { 
            autoNumber: "AMS",
      } 
  }
});
</script>
<p><br />
</p>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: { 
            autoNumber: "AMS",
      } 
  }
});
</script>
<p><strong>Note:</strong> <em>If you are unable to view the math
properly, e.g. you see a bunch of raw latex code, ensure that any
browser extensions (ublock, privacy badger, etc) are not blocking access
to mathjax.js, as this site requires mathjax to display
correctly.</em></p>
<p><br />
</p>
<div id="summary" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Summary</h1>
<hr />
<div style="margin-bottom:40px;">
<p>To take draws from the multivariate normal distribution, we leverage
the fact that linear transformations of normal random variables are also
normal. By taking a suitable decomposition of the desired covariance
matrix, multiplying this decomposition by independent normal random
vectors, and adding a constant, we can sample from any desired
parameterization of the multivariate normal distribution. Some of what
is presented here came as a result of taking <a
href="https://darrenho.github.io/">Darren Homrighausen’s</a> class on
multivariate statistics. However, two additional references were
consulted, and are available <a
href="https://www.math.kent.edu/~reichel/courses/monte.carlo/alt4.7c.pdf">here</a>
and <a
href="http://users.stat.umn.edu/~gary/classes/5401/handouts/09.mvn.handout.pdf">here</a>.</p>
</div>
</div>
<div id="transformations-of-normal-rvs" class="section level1"
number="2">
<h1><span class="header-section-number">2</span> Transformations of
Normal RVs</h1>
<hr />
<div id="the-univariate-case" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> The Univariate
Case</h2>
<hr />
<p>In order to understand how to take draws from a multivariate normal
distribution, it is first important to know that if <span
class="math inline">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span> and
<span class="math inline">\(Y = cX + k\)</span>, then <span
class="math inline">\(Y \sim \mathcal{N}(c\mu + k,
c^2\sigma^2)\)</span>. In words, linear transformations of univariate
normal random variables yield normal random variables with known
location and scale parameters.</p>
<div style="margin-top:-20px;">
<details>
<summary>
<span style="color: #0888a8;">Proof</span>
</summary>
<p>First, proving that the location and scale parameters are known in
the univariate case is a straightforward application of the fact that
expectations are a linear operator:</p>
<p><span class="math display">\[\begin{align}
&amp;\text{Let:} \nonumber \\
\nonumber \\
&amp; \quad X \sim \mathcal{N}(\mu,\sigma^2) \nonumber \\[1ex]
&amp; \quad Y = cX + k \quad \text{for constants $c$ and $k$} \nonumber
\\
\nonumber \\
&amp;\text{Then:}\nonumber \\
\nonumber \\
&amp;\quad \mathbb{E}(Y) = c\mathbb{E}(X) + k = c\mu + k
\nonumber  \\[1ex]
&amp;\quad \mathrm{Var}(Y) = c^2\mathrm{Var}(X) = c^2\sigma^2 \nonumber
\end{align}\]</span></p>
<p>And second, to show that the resulting distribution is univariate
normal, let <span class="math inline">\(F(\cdot)\)</span> be the
(normal) CDF of <span class="math inline">\(X\)</span> and <span
class="math inline">\(G(\cdot)\)</span> be the CDF of <span
class="math inline">\(Y\)</span>. Then the CDF of Y is:</p>
<p><span class="math display">\[\begin{align}
G_Y(y) &amp;= \Pr(Y \leq y) \nonumber \\[2ex]
&amp;= \Pr(cX + k \leq y)  \nonumber \\[2ex]
&amp;= \Pr\left(X \leq \frac{y-k}{c}\right) \nonumber \\[2ex]
&amp;= F_X\left(\frac{y-k}{c}\right) \\[2ex]
\end{align}\]</span></p>
<p>And differentiating to obtain the pdf of <span
class="math inline">\(Y\)</span>: <span
class="math display">\[\begin{align}
\implies g_Y(y) &amp;= \dfrac{\partial}{\partial y}
F_X\left(\frac{y-k}{c}\right)  \nonumber \\[2ex]
&amp;= f_X\left(\frac{y-k}{c}\right)\frac{1}{c} \nonumber \\[2ex]
\implies f_X\left(\frac{y-k}{c}\right)\frac{1}{c} &amp;=
\frac{1}{\sqrt{2\pi}c\sigma}
e^{\dfrac{1}{2}\left(\cfrac{\dfrac{y-k}{c}-\mu}{\sigma}\right)^{\textstyle
2}} \nonumber \\[2ex]
&amp;=\frac{1}{\sqrt{2\pi}c\sigma}
e^{\dfrac{1}{2}\left(\cfrac{\dfrac{(cx+k)-k}{c}-\mu}{\sigma}\right)^{\textstyle
2}}\nonumber \\[2ex]
&amp;=\frac{1}{\sqrt{2\pi}c\sigma}
e^{\dfrac{\left[(cx+k)-(k+c\mu)\right]^2}{2c^2\sigma^2}} \label{pdf.y}
\end{align}\]</span></p>
<p>Where \ref{pdf.y} is clearly a <span
class="math inline">\(\mathcal{N}(c\mu+k, c^2\sigma^2)\)</span>
distribution, which concludes the proof.</p>
<p><span style="float:right"><span
class="math inline">\(\blacksquare\)</span></span></p>
<p> </p>
</details>
</div>
<div style="margin-top:15px; margin-bottom:60px;">
<p>Thus, if we multiply <span class="math inline">\(X\)</span> by the
standard deviation that we desire our transformed variable to have, and
then add on a constant, we arrive at any desired normally distributed
random variable. Although this is somewhat trivial in the univariate
case due to software implementations easily drawing from arbitrary
univariate normals, this understanding proves useful when trying to draw
from a multivariate normal distribution.</p>
</div>
</div>
<div id="the-multivariate-case" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> The Multivariate
Case</h2>
<hr />
<p>The next step is to extend the univariate case to the multivariate
context by demonstrating that linear transformations of multivariate
normal random vectors are also multivariate normal. First, let</p>
<p><span class="math display">\[\begin{align}
\boldsymbol{X} &amp;\sim \mathrm{MVN}(\boldsymbol{\mu}_x,
\boldsymbol{\Sigma}_x) \nonumber \\[1ex]
\boldsymbol{Y} &amp;= \boldsymbol{CX} + \boldsymbol{k} \nonumber
\end{align}\]</span></p>
<p>Then, it follows that <span class="math display">\[\begin{align}
\boldsymbol{Y} \sim \mathrm{MVN}(\boldsymbol{C\mu_x} + \boldsymbol{k},
\boldsymbol{ C\Sigma_x C^\top}) \label{mvres}
\end{align}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\boldsymbol{Y}\)</span> is a <span
class="math inline">\(n \times 1\)</span> MVN random vector</li>
<li><span class="math inline">\(\boldsymbol{X}\)</span> is a <span
class="math inline">\(p \times 1\)</span> MVN random vector</li>
<li><span class="math inline">\(\boldsymbol{C}\)</span> is a <span
class="math inline">\(n \times p\)</span> matrix of constants</li>
<li><span class="math inline">\(\boldsymbol{k}\)</span> is a <span
class="math inline">\(n \times 1\)</span> vector of constants</li>
<li><span class="math inline">\(\boldsymbol{\mu}_x\)</span> is the <span
class="math inline">\(p \times 1\)</span> mean vector of <span
class="math inline">\(\boldsymbol{X}\)</span></li>
<li><span class="math inline">\(\boldsymbol{\Sigma}_x\)</span> is the
<span class="math inline">\(p \times p\)</span> covariance matrix of
<span class="math inline">\(\boldsymbol{X}\)</span></li>
<li><strong>Note that <span class="math inline">\(p\)</span> can be
equal to <span class="math inline">\(n\)</span></strong></li>
</ul>
<details>
<summary>
<span style="color: #0888a8;">Proof</span>
</summary>
<p>This proof calls directly on <span class="citation">Taboga (<a
href="#ref-statlect" role="doc-biblioref">2012, 447</a>)</span>, which
is also a great book for all things math-stat.</p>
<p>For proof, recall that the MGF of the MV normal distribution is <span
class="math display">\[M_X(t): \mathbb{R}^p \rightarrow \mathbb{R}=
\mathbb{E}(e^{t^\top X}) = e^{t^\top \boldsymbol{\mu }+
\frac{1}{2}t^\top \boldsymbol{\Sigma }t}\]</span> for <span
class="math inline">\(t \in \mathbb{R}^p\)</span>.</p>
<p>Then for <span class="math inline">\(t \in \mathbb{R}^n\)</span>
(dropping bold for matrices and vectors), the joint MGF of <span
class="math inline">\(Y\)</span>, <span class="math inline">\(M_Y(t):
\mathbb{R}^n \rightarrow \mathbb{R}\)</span>, is:</p>
<p><span class="math display">\[\begin{align}
M_Y(t) &amp;= \mathbb{E}(e^{t^\top Y}) \nonumber \\[2ex]
       &amp;= \mathbb{E}\left(e^{t^\top(CX + k)}\right) \nonumber
\\[2ex]
&amp;=  \mathbb{E}\left(e^{t^\top CX}e^{t^\top k}\right) \nonumber
\\[2ex]
&amp;= e^{t^\top k}\mathbb{E}\left(e^{t^\top CX}\right) \nonumber
\\[2ex]
&amp;= e^{t^\top k} M_X(tC) \nonumber \\[2ex]
&amp;= e^{t^\top k} e^{t^\top C \mu + \frac{1}{2}t^\top C \Sigma C^\top
t} \nonumber \\[2ex]
&amp;= e^{ t^\top k + t^\top C \mu  + \frac{1}{2}t^\top C \Sigma C^\top
t} \nonumber \\[2ex]
&amp;= e^{t^\top (C \mu + k) + \frac{1}{2}t^\top C \Sigma C^\top t}
\label{mgf}
\end{align}\]</span></p>
<p>And, equation \ref{mgf} is clearly the MGF of a <span
class="math inline">\(\mathrm{MVN}(\boldsymbol{C\mu + k},
\boldsymbol{C\Sigma C^\top})\)</span> distribution, which by the MGF
Uniqueness Theorem implies that <span class="math inline">\(Y\)</span>
has this distribution, which concludes the proof.</p>
<p><span style="float:right"><span
class="math inline">\(\blacksquare\)</span></span></p>
</details>
<p><br />
</p>
</div>
</div>
<div id="generating-from-the-mv-normal" class="section level1"
number="3">
<h1><span class="header-section-number">3</span> Generating from the MV
Normal</h1>
<hr />
<p><strong>Note</strong>: <em>This exposition uses a bivariate normal,
but readily extends to arbitrarily large dimensions.</em></p>
<p>In short, the steps to generate from any multivariate normal
distribution are:</p>
<ol style="list-style-type: decimal">
<li><p>Decide on a desired covariance matrix, <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span></p></li>
<li><p>Decide on a desired mean vector, <span
class="math inline">\(\boldsymbol{\mu}_y =
\boldsymbol{k}\)</span></p></li>
<li><p>Generate <span class="math inline">\(\boldsymbol{X}\)</span> as
independent standard normal <span class="math inline">\((0,1)\)</span>
random variables</p></li>
<li><p>Obtain the matrix square-root, <span
class="math inline">\(\boldsymbol{C}\)</span>, of <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span> (so that <span
class="math inline">\(\boldsymbol{CC}^\top =
\boldsymbol{\Sigma}_y\)</span>)</p></li>
<li><p>Multiply <span class="math inline">\(\boldsymbol{CX}\)</span> and
add <span class="math inline">\(\boldsymbol{CX} +
\boldsymbol{k}\)</span></p></li>
</ol>
<p>Assuming we’ve done <em>steps 1 and 2</em> already, in <em>step
3</em> we now need to generate independent univariate standard normal
random variables. To see why, recall from above that we have</p>
<p><span class="math display">\[\begin{align}
\boldsymbol{X} &amp;\sim \mathrm{MVN}(\boldsymbol{\mu}_x,
\boldsymbol{\Sigma}_x) \nonumber \\[1ex]
\boldsymbol{Y} &amp;= \boldsymbol{CX} + \boldsymbol{k} \nonumber
\\[1.5ex]
\implies \boldsymbol{Y} &amp;\sim \mathrm{MVN}(\boldsymbol{C\mu_x} +
\boldsymbol{k}, \boldsymbol{ C\Sigma_x C^\top})
\end{align}\]</span></p>
<p>Interestingly, suppose we generate the observations on <span
class="math inline">\(\boldsymbol{X}\)</span> as i.i.d. standard normal
random variables: <span class="math display">\[\begin{align}
\boldsymbol{\mu}_x &amp;= (0,0) \nonumber \\[2ex]
\boldsymbol{\Sigma}_x &amp;= \begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix} \nonumber
\end{align}\]</span></p>
<p>Then it is true that <span
class="math inline">\(\boldsymbol{\Sigma}_x = \boldsymbol{I}\)</span>.
This result lends nicely to <em>step 4</em> (find the matrix square-root
of <span class="math inline">\(\boldsymbol{\Sigma}_y\)</span>), because
to obtain <span class="math inline">\(\boldsymbol{Y} \sim
\mathrm{MVN}(\boldsymbol{\mu}_y, \boldsymbol{\Sigma}_y)\)</span>, we
simply have to find a suitable matrix <span
class="math inline">\(\boldsymbol{C}\)</span> such that multiplying
<span class="math inline">\(\boldsymbol{CX}\)</span> yields<span
class="math display">\[\mathrm{Cov}(\boldsymbol{Y}) =
\mathrm{Cov}(\boldsymbol{CX}) = \boldsymbol{C\Sigma}_x
\boldsymbol{C}^\top = \boldsymbol{CIC}^\top =
\boldsymbol{CC}^\top\]</span> as already proven. In order to arrive at
this matrix of constants, note that the square-root of a matrix, <span
class="math inline">\(\boldsymbol{A}\)</span>, is any matrix, <span
class="math inline">\(\boldsymbol{B}\)</span>, such that <span
class="math inline">\(\boldsymbol{BB}^\top = \boldsymbol{A}\)</span>.<a
href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> This
implies that the matrix of constants, <span
class="math inline">\(\boldsymbol{C}\)</span>, in <span
class="math inline">\(\boldsymbol{CX}\)</span> is in fact the matrix
square-root of <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span>, directly analogous
to the univariate case in which we multiplied <span
class="math inline">\(X\sigma_y\)</span>. Thus, by generating i.i.d.
standard normal variables in step 3, we then deduce that <span
class="math inline">\(\boldsymbol{C}\)</span> must be the matrix
square-root of <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span> in order to get the
desired structure for <span
class="math inline">\(\boldsymbol{Y}\)</span>. In <em>step 5</em>, we
can finally add on a vector of constants, <span
class="math inline">\(\boldsymbol{k} = \boldsymbol{\mu}_y\)</span>, to
get the desired mean vector for <span
class="math inline">\(\boldsymbol{Y}\)</span>, because <span
class="math inline">\(\boldsymbol{\mu}_x = \boldsymbol{0}\)</span>.</p>
<p>To find the matrix square-root of <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span>, two factorizations
of <span class="math inline">\(\boldsymbol{\Sigma}_y =
\boldsymbol{CC^\top}\)</span> immediately come to mind, although several
others can also work:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Cholesky decomposition</strong> – <span
class="math inline">\(\boldsymbol{LL}^\top\)</span> where <span
class="math inline">\(\boldsymbol{L}\)</span> is lower-triangular. This
is unique for positive definite matrices, which all valid covariance
matrices are.</p></li>
<li><p><strong>Singular values decomposition</strong> (SVD) – <span
class="math inline">\(\boldsymbol{UDV}^\top\)</span>, where <span
class="math inline">\(\boldsymbol{U}\)</span> and <span
class="math inline">\(\boldsymbol{V}\)</span> are orthogonal matrices
whose columns are the left and right singular vectors, respectively, and
<span class="math inline">\(\boldsymbol{D}\)</span> is a diagonal matrix
containing the singular values. Because of the orthogonal and diagonal
matrices, this is geometrically a rotation, elongation, and rotation.
<strong>Note</strong> that for real, symmetric, positive-definite
matrices, this is identical to the spectral decomposition.<a href="#fn2"
class="footnote-ref" id="fnref2"><sup>2</sup></a></p></li>
</ol>
<p><br />
</p>
<hr />
<div id="via-cholesky" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Via Cholesky</h2>
<hr />
<p>To obtain the matrix square-root, <span
class="math inline">\(\boldsymbol{C}\)</span>, via the Cholesky
decomposition decompose <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span> as <span
class="math display">\[\boldsymbol{\Sigma}_y =
\boldsymbol{LL}^\top\]</span> and multiply <span
class="math display">\[\boldsymbol{Y} = \boldsymbol{LX}\]</span> which
yields <span class="math display">\[\boldsymbol{Y} \sim (\boldsymbol{0},
\boldsymbol{LL^\top})\]</span> which has exactly the covariance
structure that we wanted, as <span
class="math inline">\(\boldsymbol{L}\)</span> is equivalent to the
matrix <span class="math inline">\(\boldsymbol{C}\)</span> that we were
looking for.</p>
<p><br />
</p>
</div>
<div id="via-svd" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Via SVD</h2>
<hr />
For the SVD, decompose <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span> as <span
class="math display">\[\boldsymbol{\Sigma}_y = \boldsymbol{UDV}^\top =
\boldsymbol{UDU}^\top\]</span> The last equality follows in this case
because <span class="math inline">\(\boldsymbol{\Sigma}_y\)</span> is a
symmetric, positive definite matrix.
<details>
<summary>
<span style="color: #0888a8;">Proof</span>
</summary>
<p><br />
</p>
<p>Suppose we take the SVD of a symmetric matrix <span
class="math inline">\(A\)</span>. Then the left singluar vectors, <span
class="math inline">\(U\)</span>, are the eigenvectors of <span
class="math inline">\(AA^\top\)</span>, while the right singular
vectors, <span class="math inline">\(V\)</span>, are the eigenvectors of
<span class="math inline">\(A^\top A\)</span> (see <a
href="https://math.mit.edu/classes/18.095/2016IAP/lec2/SVD_Notes.pdf">this</a>
link for proof). However, since <span class="math inline">\(A\)</span>
is symmetric, <span class="math display">\[A = A^\top \implies AA^\top =
A^\top A \implies U = V\]</span></p>
<p><span style="float:right"><span
class="math inline">\(\blacksquare\)</span></span></p>
</details>
<p><br />
</p>
<p>Finally, pre-multiplying the univariate normals in <span
class="math inline">\(X\)</span> by the matrix square-root, <span
class="math inline">\(\boldsymbol{C}\)</span>, of <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span> yields (dropping
bolding)</p>
<p><span class="math display">\[\begin{align}
Y= CX &amp;= UD^{1/2} X \nonumber \\[1ex]
\implies Y &amp;\sim \left(\boldsymbol{0}, UD^{1/2}\Sigma_x
(UD^{1/2})^\top \right) \nonumber \\[1ex]
&amp; \sim \left(\boldsymbol{0}, UD^{1/2} I (UD^{1/2})^\top \right)
\nonumber \\[1ex]
&amp; \sim \left(\boldsymbol{0}, UD^{1/2}D^{1/2}U^\top\right) \nonumber
\\[1ex]
&amp; \sim \left(\boldsymbol{0} , UDU^\top\right) \nonumber \\[1ex]
&amp; \sim \left(\boldsymbol{0} , \Sigma_y\right) \nonumber \\[1ex]
\end{align}\]</span></p>
<p>So to obtain the desired covariance <span
class="math inline">\(\boldsymbol{\Sigma}_y\)</span> from <span
class="math inline">\(X\)</span> we simply set <span
class="math inline">\(\boldsymbol{C} = \boldsymbol{UD}^{1/2}\)</span>
and premultiply <span class="math inline">\(\boldsymbol{CX}\)</span>.<a
href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p><br />
</p>
</div>
</div>
<div id="programming-in-r" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Programming in R</h1>
<hr />
<div id="the-function" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> The function</h2>
<hr />
<p>To do this in R, we follow the steps outlined previously. Thus, we
first decide on the desired mean vector, <span
class="math inline">\(\boldsymbol{\mu}_y\)</span>, and covariance
matrix, <span class="math inline">\(\boldsymbol{\Sigma}_y\)</span>.
Recall also that a valid, full-rank covariance matrix is
positive-definite.<a href="#fn4" class="footnote-ref"
id="fnref4"><sup>4</sup></a></p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>mu.y <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">246</span>, <span class="sc">-</span><span class="fl">1.3</span>, <span class="fl">1.645</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>sigma.y <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,    .<span class="dv">66</span>, <span class="sc">-</span><span class="fl">1.2</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>                   .<span class="dv">66</span>,  .<span class="dv">75</span>, <span class="sc">-</span>.<span class="dv">75</span>,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                  <span class="sc">-</span><span class="fl">1.2</span>, <span class="sc">-</span>.<span class="dv">75</span>,  <span class="fl">2.5</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">byrow=</span>T)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#desired cov</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>sigma.y</span></code></pre></div>
<pre class="bg-success"><code>##       [,1]  [,2]  [,3]
## [1,]  2.00  0.66 -1.20
## [2,]  0.66  0.75 -0.75
## [3,] -1.20 -0.75  2.50</code></pre>
<div class="sourceCode" id="cb3"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#check pos def</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all</span>(<span class="fu">eigen</span>(sigma.y)<span class="sc">$</span>values <span class="sc">&gt;</span> <span class="dv">0</span>)</span></code></pre></div>
<pre class="bg-success"><code>## [1] TRUE</code></pre>
<p> </p>
<p>Second, we’ll simulate some i.i.d. multivariate standard normal data
in 3 dimensions.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#simulate trivariate iid standard normal </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">3</span>), <span class="at">nrow=</span><span class="dv">3</span>)</span></code></pre></div>
<p><br />
</p>
<p>And then finally we take the Cholesky and SVD of the desired
covariance, multiply <span class="math inline">\(\boldsymbol{X}\)</span>
by the appropriate matrix <span
class="math inline">\(\boldsymbol{C}\)</span>, and then add on the
constant to get the desired mean.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Via cholesky</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>chol.sig.y <span class="ot">=</span> <span class="fu">chol.default</span>(sigma.y)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y.chol <span class="ot">=</span> <span class="fu">t</span>(chol.sig.y) <span class="sc">%*%</span> x <span class="co"># R returns the upper-triangular, L^t by default</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Via svd</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>svd.sig.y <span class="ot">=</span> <span class="fu">svd</span>(sigma.y)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>u <span class="ot">=</span> svd.sig.y<span class="sc">$</span>u</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> svd.sig.y<span class="sc">$</span>d</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>sqrt.sig <span class="ot">=</span> u<span class="sc">%*%</span><span class="fu">diag</span>(d)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>y.svd <span class="ot">=</span>  sqrt.sig <span class="sc">%*%</span> x </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># add on mean </span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">#(transpose for taking the covariance of a matrix in R on next lines)</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>y.svd <span class="ot">=</span> <span class="fu">t</span>(y.svd <span class="sc">+</span> mu.y)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>y.chol <span class="ot">=</span> <span class="fu">t</span>(y.chol <span class="sc">+</span> mu.y)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># results </span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">chol =</span> <span class="fu">list</span>(<span class="at">mean=</span><span class="fu">apply</span>(y.chol, <span class="dv">2</span>, mean),</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>                 <span class="at">cov=</span><span class="fu">cov</span>(y.chol)),</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>     <span class="at">svd  =</span> <span class="fu">list</span>(<span class="at">mean=</span><span class="fu">apply</span>(y.svd, <span class="dv">2</span>, mean),</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>                 <span class="at">cov=</span><span class="fu">cov</span>(y.svd)),</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">desired_cov =</span> sigma.y,</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>     <span class="at">desired_mean =</span> mu.y)</span></code></pre></div>
<pre class="bg-success"><code>## $chol
## $chol$mean
## [1] -0.2486621 -1.3062175  1.6456811
## 
## $chol$cov
##            [,1]       [,2]       [,3]
## [1,]  1.9967534  0.6670104 -1.1774324
## [2,]  0.6670104  0.7474750 -0.7282327
## [3,] -1.1774324 -0.7282327  2.4383260
## 
## 
## $svd
## $svd$mean
## [1] -0.2488531 -1.3014936  1.6370299
## 
## $svd$cov
##           [,1]       [,2]       [,3]
## [1,]  1.976689  0.6528620 -1.2072767
## [2,]  0.652862  0.7355421 -0.7339955
## [3,] -1.207277 -0.7339955  2.5134166
## 
## 
## $desired_cov
##       [,1]  [,2]  [,3]
## [1,]  2.00  0.66 -1.20
## [2,]  0.66  0.75 -0.75
## [3,] -1.20 -0.75  2.50
## 
## $desired_mean
## [1] -0.246 -1.300  1.645</code></pre>
<p><br />
</p>
<p>From the above output, it is clear that the desired covariance
structure is achieved. So we can finally write our own little function
that generates multivariate normal samples! In fact, the function below
is virtually indistinguishable from the <a
href="https://rdrr.io/cran/MASS/src/R/mvrnorm.R">source-code</a> for the
<code>MASS</code> package’s <code>mvrnorm</code> function.</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>my.mvrnorm <span class="ot">=</span> <span class="cf">function</span>(sigma.y, <span class="at">mu.y =</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">ncol</span>(sigma.y)), n, <span class="at">method=</span><span class="st">&quot;svd&quot;</span>){</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  method <span class="ot">=</span> <span class="fu">match.arg</span>(method, <span class="at">choices =</span> <span class="fu">c</span>(<span class="st">&quot;svd&quot;</span>, <span class="st">&quot;cholesky&quot;</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  pdef <span class="ot">=</span> <span class="fu">all</span>(<span class="fu">eigen</span>(sigma.y)<span class="sc">$</span>values <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>pdef) <span class="fu">stop</span>(<span class="st">&quot;Desired covariance not positive definite.&quot;</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">isSymmetric</span>(sigma.y)) <span class="fu">stop</span>(<span class="st">&quot;Covariance is not symmetric.&quot;</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">ncol</span>(sigma.y) <span class="sc">!=</span> <span class="fu">length</span>(mu.y)) <span class="fu">stop</span>(<span class="st">&quot;Dimensions of mean and covariance inconsistent.&quot;</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">*</span><span class="fu">length</span>(mu.y)), <span class="at">nrow =</span> <span class="fu">length</span>(mu.y))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(method <span class="sc">==</span> <span class="st">&quot;svd&quot;</span>){</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    svd.sig <span class="ot">=</span> <span class="fu">svd</span>(sigma.y)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> svd.sig<span class="sc">$</span>u <span class="sc">%*%</span> <span class="fu">diag</span>(svd.sig<span class="sc">$</span>d<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)) <span class="sc">%*%</span> x <span class="sc">+</span> mu.y</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">t</span>(y))</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    chol.sig <span class="ot">=</span> <span class="fu">t</span>(<span class="fu">chol.default</span>(sigma.y))</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> chol.sig <span class="sc">%*%</span> x <span class="sc">+</span> mu.y</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">t</span>(y))</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><br />
</p>
</div>
<div id="which-method-is-better" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Which method is
better?</h2>
<hr />
<p>We’ve learned that two factorizations work, but which one is
“better,” numerically? This may depend on how we define “better,” but
lets try and find out. First, for simplicity we will only look at the
accuracy of the covariance. Second, lets say that a factorization is
better if it minimizes <span class="math inline">\(max_{ij} |Cov(x_{i},
x_{j}) - D_{ij}|\)</span> where <span
class="math inline">\(D_{ij}\)</span> is each element of the desired
covariance matrix. That is, which method minimizes the maximum absolute
deviation from the desired covariance structure.</p>
<p>Taking this objective in mind, we can explore this by the monte carlo
method. We’ll first define a function that returns the value of the
objective, as well as the sample size, and decomposition used, and then
compare the loss after several iterations for each sample size.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>mv.loss <span class="ot">=</span> <span class="cf">function</span>(n, sigma.y){</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">=</span> n</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">3</span>), <span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># chol</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  chol.sig.y <span class="ot">=</span> <span class="fu">chol.default</span>(sigma.y)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  y.chol <span class="ot">=</span> <span class="fu">t</span>(chol.sig.y) <span class="sc">%*%</span> x </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  loss.chol <span class="ot">=</span> <span class="fu">max</span>( <span class="fu">abs</span>( <span class="fu">cov</span>(<span class="fu">t</span>(y.chol)) <span class="sc">-</span> sigma.y) )</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Via svd</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  svd.sig.y <span class="ot">=</span> <span class="fu">svd</span>(sigma.y)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  u <span class="ot">=</span> svd.sig.y<span class="sc">$</span>u</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  d <span class="ot">=</span> svd.sig.y<span class="sc">$</span>d</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  sig.sqrt <span class="ot">=</span> u<span class="sc">%*%</span><span class="fu">diag</span>(d)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  y.svd <span class="ot">=</span>  sig.sqrt <span class="sc">%*%</span> x </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>  loss.svd <span class="ot">=</span> <span class="fu">max</span>( <span class="fu">abs</span>( <span class="fu">cov</span>(<span class="fu">t</span>(y.svd)) <span class="sc">-</span> sigma.y) )</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(<span class="fu">c</span>(<span class="at">chol =</span> loss.chol, <span class="at">svd =</span> loss.svd, <span class="at">n=</span>n))</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><br />
</p>
<p>And lets make sure its working as expected, using the desired
covariance previously defined:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mv.loss</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">sigma.y =</span> sigma.y)</span></code></pre></div>
<pre class="bg-success"><code>##        chol         svd           n 
##   0.5096003   0.3819846 100.0000000</code></pre>
<p><br />
</p>
<p>And finally, now that we know the function works, we can do several
iterations at each sample size to see which method converges
fastest.</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>RhpcBLASctl<span class="sc">::</span><span class="fu">blas_set_num_threads</span>(<span class="dv">1</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>RhpcBLASctl<span class="sc">::</span><span class="fu">omp_set_num_threads</span>(<span class="dv">1</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># get things ready for parallel run, plotting</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>pks <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;parallel&quot;</span>, <span class="st">&quot;dplyr&quot;</span>, <span class="st">&quot;ggplot2&quot;</span>, <span class="st">&quot;reshape2&quot;</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(<span class="fu">sapply</span>(pks, library, <span class="at">character.only=</span>T))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="fu">RNGkind</span>(<span class="st">&quot;L&#39;Ecuyer-CMRG&quot;</span>) <span class="co"># for parallel reproducibility</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">167492</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Grid of sample sizes</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>niter <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">60</span>, <span class="dv">125</span>, <span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">750</span>, <span class="dv">1000</span>, <span class="dv">2500</span>, <span class="dv">5000</span>, <span class="dv">7500</span>, <span class="dv">10000</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>n.grid <span class="ot">=</span> <span class="fu">rep</span>(n, <span class="at">each =</span> niter)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># run sims, summarize, plot</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">mclapply</span>(n.grid, mv.loss, <span class="at">sigma.y=</span>sigma.y, </span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>               <span class="at">mc.preschedule=</span>T,</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>               <span class="at">mc.cores =</span> (parallel<span class="sc">::</span><span class="fu">detectCores</span>()<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">=</span> <span class="fu">as.data.frame</span>(<span class="fu">do.call</span>(rbind, res))</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>summaries <span class="ot">=</span> dat <span class="sc">%&gt;%</span> </span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n) <span class="sc">%&gt;%</span> </span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean.chol =</span> <span class="fu">mean</span>(chol),</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>            <span class="at">mean.svd  =</span> <span class="fu">mean</span>(svd))</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>summaries <span class="ot">=</span> <span class="fu">melt</span>(summaries, </span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>                 <span class="at">id.vars=</span><span class="st">&quot;n&quot;</span>, </span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>                 <span class="at">measure.vars =</span> <span class="fu">c</span>(<span class="st">&quot;mean.chol&quot;</span>,</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;mean.svd&quot;</span>))</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>summaries<span class="sc">$</span>n <span class="ot">=</span> <span class="fu">as.factor</span>(summaries<span class="sc">$</span>n)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>summaries, <span class="fu">aes</span>(<span class="at">x=</span>n)) <span class="sc">+</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> value, <span class="at">color=</span>variable, <span class="at">shape=</span>variable),</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>             <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="at">width=</span>.<span class="dv">5</span>),</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>             <span class="at">size=</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Set1&quot;</span>, </span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>                     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Cholesky&quot;</span>, <span class="st">&quot;SVD&quot;</span>)) <span class="sc">+</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_shape_discrete</span>(<span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;Cholesky&quot;</span>, <span class="st">&quot;SVD&quot;</span>)) <span class="sc">+</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Average of Max Absolute Deviation for Covariance of MVN&quot;</span>,</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Cholesky vs. SVD&quot;</span>,</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>       <span class="at">x=</span> <span class="st">&quot;N&quot;</span>,</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>       <span class="at">y=</span> <span class="st">&quot;Avg. Max Absolute Deviation&quot;</span>,</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">&quot;Method&quot;</span>,</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">shape =</span> <span class="st">&quot;Method&quot;</span>) <span class="sc">+</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="fu">c</span>(.<span class="dv">85</span>,.<span class="dv">85</span>)) </span></code></pre></div>
<p><img src="mvnorm_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p><br />
</p>
<p>From these results, it appears as though the two perform roughly the
same in terms of max absolute deviations from the desired covariance
structure, on average. However, it looks like they may be slightly
different in small samples, so lets take a look to be sure.</p>
<p><br />
</p>
<p><img src="mvnorm_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Lastly, then, the two approaches are equal on average, even in small
samples.</p>
</div>
</div>
<div id="references-and-footnotes" class="section level1" number="5">
<h1><span class="header-section-number">5</span> References and
Footnotes</h1>
<hr />
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-statlect" class="csl-entry">
Taboga, Marco. 2012. <span>“Lectures on Probability and
Statistics.”</span> StatLect.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>This is an alternative definition of the matrix
square-root. More often, it is defined as <span
class="math inline">\(A=BB\)</span> instead of <span
class="math inline">\(A=BB^\top\)</span><a href="#fnref1"
class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>One of the advantages of the SVD then is that it nests
the well-known spectral decomposition, while always existing. In other
words, there are no restrictions on the existence of the SVD, unlike the
spectral decomposition. Moreover, the SVD tends to be more <a
href="https://cims.nyu.edu/~donev/Teaching/NMI-Fall2010/Lecture5.handout.pdf">numerically
stable</a>, at the cost of relative inefficiency.<a href="#fnref2"
class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>We could also use <span
class="math inline">\(\boldsymbol{UD^{1/2}U^\top}\)</span> as the matrix
square-root, although this requires more computations.<a href="#fnref3"
class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>An interesting way to understand why (other than
mathematical necessity) is that the correlation between some of the
variables would be <span class="math inline">\(\geq 1\)</span> or <span
class="math inline">\(\leq -1\)</span> if this did not hold, suggesting
either an invalid correlation, or perfectly colinear variables.<a
href="#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
